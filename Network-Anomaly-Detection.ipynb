{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Download Datset and Understand the Format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = gzip.open('kddcup.data_10_percent.gz', 'r').readlines()\n",
    "testDataset = gzip.open('corrected.gz', 'r').readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maps from categorical data to numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrNames = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label']\n",
    "protocol_type = {'tcp': 0, 'udp': 1, 'icmp': 2}\n",
    "service = {'aol': 0, 'auth': 1, 'bgp': 2, 'courier': 3, 'csnet_ns': 4, 'ctf': 5, 'daytime': 6, 'discard': 7, 'domain': 8, 'domain_u': 9, 'echo': 10, 'eco_i': 11, 'ecr_i': 12, 'efs': 13, 'exec': 14, 'finger': 15, 'ftp': 16, 'ftp_data': 17, 'gopher': 18, 'harvest': 19, 'hostnames': 20, 'http': 21, 'http_2784': 22, 'http_443': 23, 'http_8001': 24, 'imap4': 25, 'IRC': 26, 'iso_tsap': 27, 'klogin': 28, 'kshell': 29, 'ldap': 30, 'link': 31, 'login': 32, 'mtp': 33, 'name': 34, 'netbios_dgm': 35, 'netbios_ns': 36, 'netbios_ssn': 37, 'netstat': 38, 'nnsp': 39, 'nntp': 40, 'ntp_u': 41, 'other': 42, 'pm_dump': 43, 'pop_2': 44, 'pop_3': 45, 'printer': 46, 'private': 47, 'red_i': 48, 'remote_job': 49, 'rje': 50, 'shell': 51, 'smtp': 52, 'sql_net': 53, 'ssh': 54, 'sunrpc': 55, 'supdup': 56, 'systat': 57, 'telnet': 58, 'tftp_u': 59, 'tim_i': 60, 'time': 61, 'urh_i': 62, 'urp_i': 63, 'uucp': 64, 'uucp_path': 65, 'vmnet': 66, 'whois': 67, 'X11': 68, 'Z39_50': 69, 'icmp': 70}\n",
    "flag = {'OTH': 0, 'REJ': 1, 'RSTO': 2, 'RSTOS0': 3, 'RSTR': 4, 'S0': 5, 'S1': 6, 'S2': 7, 'S3': 8, 'SF': 9, 'SH': 10}\n",
    "labels = {'normal': 0, 'back': 1, 'buffer_overflow': 2, 'ftp_write': 3, 'guess_passwd': 4, 'imap': 5, 'ipsweep': 6, 'land': 7, 'loadmodule': 8, 'multihop': 9, 'neptune': 10, 'nmap': 11, 'perl': 12, 'phf': 13, 'pod': 14, 'portsweep': 15, 'rootkit': 16, 'satan': 17, 'smurf': 18, 'spy': 19, 'teardrop': 20, 'warezclient': 21, 'warezmaster': 22, 'snmpgetattack': 23, 'snmpguess': 24, 'httptunnel': 25, 'sendmail': 26, 'named': 27, 'xlock': 28, 'xsnoop': 29, 'worm': 30, 'xterm': 31, 'ps': 32, 'sqlattack': 33, 'udpstorm': 34, 'mailbomb': 35, 'saint': 36, 'apache2': 37, 'mscan': 38, 'processtable': 39,'icmp': 40}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the categorical features to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trainDataset)):\n",
    "    \n",
    "    trainDataset[i] = trainDataset[i].decode('utf-8') # convert from bytes to string\n",
    "    if trainDataset[i].endswith('.\\n'): \n",
    "        trainDataset[i] = trainDataset[i].replace('.\\n', '') # remove '.\\n'\n",
    "    trainDataset[i] = trainDataset[i].strip().split(',') # split by comma\n",
    "    \n",
    "    for j in range(len(trainDataset[i])):\n",
    "        try:\n",
    "            trainDataset[i][j] = int(trainDataset[i][j]) # convert to int\n",
    "        except ValueError:\n",
    "            try:\n",
    "                trainDataset[i][j] = float(trainDataset[i][j]) # convert to float\n",
    "            except ValueError: # convert categorical data to numerical data\n",
    "                if j == 1: \n",
    "                    trainDataset[i][j] = protocol_type[trainDataset[i][j]]\n",
    "                elif j == 2:\n",
    "                    trainDataset[i][j] = service[trainDataset[i][j]]\n",
    "                elif j == 3:\n",
    "                    trainDataset[i][j] = flag[trainDataset[i][j]]\n",
    "                elif j == 41:\n",
    "                    trainDataset[i][j] = labels[trainDataset[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from bytes to string and change categorical data to numerical data\n",
    "for i in range(len(testDataset)):\n",
    "    \n",
    "    testDataset[i] = testDataset[i].decode('utf-8') # convert from bytes to string\n",
    "    if testDataset[i].endswith('.\\n'):\n",
    "        testDataset[i] = testDataset[i].replace('.\\n', '') # remove '.\\n'\n",
    "    testDataset[i] = testDataset[i].strip().split(',') # split by comma\n",
    "    \n",
    "    for j in range(len(testDataset[i])):\n",
    "        try:\n",
    "            testDataset[i][j] = int(testDataset[i][j]) # convert to int\n",
    "        except ValueError:\n",
    "            try:\n",
    "                testDataset[i][j] = float(testDataset[i][j]) # convert to float\n",
    "            except ValueError: # convert categorical data to numerical data\n",
    "                if j == 1:\n",
    "                    testDataset[i][j] = protocol_type[testDataset[i][j]]\n",
    "                elif j == 2:\n",
    "                    testDataset[i][j] = service[testDataset[i][j]]\n",
    "                elif j == 3:\n",
    "                    testDataset[i][j] = flag[testDataset[i][j]]\n",
    "                elif j == 41:\n",
    "                    testDataset[i][j] = labels[testDataset[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate rows\n",
    "trainDataset = list(set(tuple(row) for row in trainDataset))\n",
    "testDataset = list(set(tuple(row) for row in testDataset))\n",
    "\n",
    "trainDataset = list(list(row) for row in trainDataset)\n",
    "testDataset = list(list(row) for row in testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "testLabels = []\n",
    "for i in range(len(testDataset)):\n",
    "    testLabels.append(testDataset[i][41])\n",
    "    testDataset[i].pop(41)\n",
    "trainLabels = []\n",
    "for i in range(len(trainDataset)):\n",
    "    trainLabels.append(trainDataset[i][41])\n",
    "    trainDataset[i].pop(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 0.01 from trainDataset for testing purposes\n",
    "train10 = trainDataset[:int(len(trainDataset)*0.01)]\n",
    "trainLabels10 = trainLabels[:int(len(trainLabels)*0.01)]\n",
    "test10 = testDataset[:int(len(testDataset)*0.01)]\n",
    "testLabels10 = testLabels[:int(len(testLabels)*0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train10 = scale(train10, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "scaled_test10 = scale(test10, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "scaled_train = scale(trainDataset, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "scaled_test = scale(testDataset, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class k_medoids:\n",
    "    def __init__(self, k = 2, max_iter = 300, has_converged = False):\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        self.has_converged = has_converged\n",
    "        self.medoids_cost = []\n",
    "        \n",
    "    def initMedoids(self, X):\n",
    "        \n",
    "        self.medoids = []\n",
    "        \n",
    "        indexes = np.random.randint(0, len(X)-1,self.k)\n",
    "        self.medoids = X[indexes]\n",
    "        \n",
    "        for i in range(0,self.k):\n",
    "            self.medoids_cost.append(0)\n",
    "        \n",
    "    def isConverged(self, new_medoids):\n",
    "        \n",
    "        return set([tuple(x) for x in self.medoids]) == set([tuple(x) for x in new_medoids])\n",
    "        \n",
    "    def updateMedoids(self, X, labels):\n",
    "        self.has_converged = True\n",
    "        \n",
    "        clusters = []\n",
    "        for i in range(0,self.k):\n",
    "            cluster = []\n",
    "            for j in range(len(X)):\n",
    "                if (labels[j] == i):\n",
    "                    cluster.append(X[j])\n",
    "            clusters.append(cluster)\n",
    "        \n",
    "        new_medoids = []\n",
    "        for i in range(0, self.k):\n",
    "            new_medoid = self.medoids[i]\n",
    "            old_medoids_cost = self.medoids_cost[i]\n",
    "            for j in range(len(clusters[i])):\n",
    "                \n",
    "                cur_medoids_cost = 0\n",
    "                for dpoint_index in range(len(clusters[i])):\n",
    "                    cur_medoids_cost += pairwise_distances(np.array(clusters[i][j]).reshape(1,-1), np.array(clusters[i][dpoint_index]).reshape(1,-1))\n",
    "                \n",
    "                if cur_medoids_cost < old_medoids_cost:\n",
    "                    new_medoid = clusters[i][j]\n",
    "                    old_medoids_cost = cur_medoids_cost\n",
    "            \n",
    "            new_medoids.append(new_medoid)\n",
    "        \n",
    "        if not self.isConverged(new_medoids):\n",
    "            self.medoids = new_medoids\n",
    "            self.has_converged = False\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.initMedoids(X)\n",
    "        \n",
    "        for i in tqdm(range(self.max_iter)):\n",
    "            cur_labels = []\n",
    "            for medoid in range(0,self.k):\n",
    "                self.medoids_cost[medoid] = 0\n",
    "                for k in range(len(X)):\n",
    "                    d_list = []                    \n",
    "                    for j in range(0,self.k):\n",
    "                        d_list.append(pairwise_distances(np.array(self.medoids[j]).reshape(1,-1), np.array(X[k]).reshape(1,-1)))\n",
    "                    cur_labels.append(d_list.index(min(d_list)))\n",
    "                    \n",
    "                    self.medoids_cost[medoid] += min(d_list)\n",
    "                                \n",
    "            self.updateMedoids(X, cur_labels)\n",
    "            \n",
    "            if self.has_converged:\n",
    "                break\n",
    "\n",
    "        return np.array(self.medoids)\n",
    "\n",
    "        \n",
    "    def predict(self,data):\n",
    "        pred = []\n",
    "        for i in range(len(data)):\n",
    "            d_list = []\n",
    "            for j in range(len(self.medoids)):\n",
    "                d_list.append(pairwise_distances(np.array(self.medoids[j]).reshape(1,-1),np.array(data[i]).reshape(1,-1)))\n",
    "                \n",
    "            pred.append(d_list.index(min(d_list)))\n",
    "            \n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = k_medoids(k=15, max_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:20<01:22,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "meds = d.fit(np.array(scaled_train[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 197564.96it/s]\n"
     ]
    }
   ],
   "source": [
    "clusterLabels = {}\n",
    "trainClusters = d.predict(np.array(scaled_train[0:100]))\n",
    "medLabels = []\n",
    "for i in tqdm(range(len(trainClusters))):\n",
    "    if trainClusters[i] not in clusterLabels.keys():\n",
    "        clusterLabels[trainClusters[i]] = [trainLabels10[i]]\n",
    "    else:\n",
    "        clusterLabels[trainClusters[i]].append(trainLabels10[i])\n",
    "\n",
    "for key in clusterLabels:\n",
    "    medLabels.append(max(set(clusterLabels[key]), key = clusterLabels[key].count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = d.predict(np.array(scaled_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy(predict, trueLabels, medLabels):\n",
    "    acc = 0\n",
    "    for i in range(len(predict)):\n",
    "        if trueLabels[i] == 0 and medLabels[predict[i]] == 0:\n",
    "            acc += 1\n",
    "        elif trueLabels[i] != 0 and medLabels[predict[i]] != 0:\n",
    "            acc += 1\n",
    "    return acc/len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision\n",
    "def calcPercision(predict, trueLabels,medLabels):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    for i in range(len(predict)):\n",
    "        if trueLabels[i] == 0 and medLabels[predict[i]] == 0:\n",
    "            TP += 1\n",
    "        elif trueLabels[i] == 0 and medLabels[predict[i]] != 0:\n",
    "            FP += 1\n",
    "    return TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate recall\n",
    "def calcRecall(predict, trueLabels,medLabels):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(predict)):\n",
    "        if trueLabels[i] == 0 and medLabels[predict[i]] == 0:\n",
    "            TP += 1\n",
    "        elif trueLabels[i] != 0 and medLabels[predict[i]] == 0:\n",
    "            FN += 1\n",
    "    return TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate F1 score\n",
    "def calcF1(precision, recall):\n",
    "    return 2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate conditional entropy\n",
    "def calcEntropy(predict, trueLabels,medLabels):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    for i in range(len(predict)):\n",
    "        if trueLabels[i] == 0 and medLabels[predict[i]] == 0:\n",
    "            TP += 1\n",
    "        elif trueLabels[i] == 0 and medLabels[predict[i]] != 0:\n",
    "            FP += 1\n",
    "        elif trueLabels[i] != 0 and medLabels[predict[i]] == 0:\n",
    "            FN += 1\n",
    "        elif trueLabels[i] != 0 and medLabels[predict[i]] != 0:\n",
    "            TN += 1\n",
    "    return -TP/len(predict)*np.log2(TP/len(predict)) - FP/len(predict)*np.log2(FP/len(predict)) - FN/len(predict)*np.log2(FN/len(predict)) - TN/len(predict)*np.log2(TN/len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6495581633049126\n",
      "Precision:  0.7850061569928829\n",
      "Recall:  0.6914351894405941\n",
      "F1 score:  0.735255595738442\n",
      "Conditional entropy:  1.798102710253255\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", calcAccuracy(result, testLabels, medLabels))\n",
    "print(\"Precision: \", calcPercision(result, testLabels, medLabels))\n",
    "print(\"Recall: \", calcRecall(result, testLabels, medLabels))\n",
    "print(\"F1 score: \", calcF1(calcPercision(result, testLabels,medLabels), calcRecall(result, testLabels,medLabels)))\n",
    "print(\"Conditional entropy: \", calcEntropy(result, testLabels,medLabels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
